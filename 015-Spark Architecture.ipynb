{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f809d514-b461-4921-b735-1dec51aa9d9a",
   "metadata": {},
   "source": [
    "## Spark execution modes:\n",
    "* standalone\n",
    "* standalone - cluster mode\n",
    "* yarn (most popular)\n",
    "* mesos\n",
    "* kubernetes\n",
    "* local (development purpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc685beb-dffa-4d54-979a-8784c512161b",
   "metadata": {},
   "source": [
    "* executor -> driver + workers -> slots (cores)\n",
    "* driver allocates tasks to empty slots\n",
    "\n",
    "* spark application\n",
    "\n",
    "* job -> stage\n",
    "\n",
    "\n",
    "environment -> runtime behaviour of the spark applicaton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6489f13a-f32e-4644-9d5b-f515d9140ea5",
   "metadata": {},
   "source": [
    "## Spark adaptive (query) execution properties\n",
    "* `spark` (SparkSession - hive)\n",
    "* `spark.conf` (runtime config)\n",
    "    * `spark.conf.get`\n",
    "    * `spark.conf.set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b00d1e1-0da3-4e8d-b726-011db3eaaf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:01:44.071539Z",
     "iopub.status.busy": "2024-06-25T21:01:44.070943Z",
     "iopub.status.idle": "2024-06-25T21:01:50.867255Z",
     "shell.execute_reply": "2024-06-25T21:01:50.866931Z",
     "shell.execute_reply.started": "2024-06-25T21:01:44.071508Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/25 23:01:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('instance').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd178254-02c4-48de-91fb-95ff2add54fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:01:52.960751Z",
     "iopub.status.busy": "2024-06-25T21:01:52.959936Z",
     "iopub.status.idle": "2024-06-25T21:01:52.981869Z",
     "shell.execute_reply": "2024-06-25T21:01:52.981232Z",
     "shell.execute_reply.started": "2024-06-25T21:01:52.960702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8643322-8216-4415-9787-bb2cabe8523f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:02:49.120268Z",
     "iopub.status.busy": "2024-06-25T21:02:49.119721Z",
     "iopub.status.idle": "2024-06-25T21:02:49.137320Z",
     "shell.execute_reply": "2024-06-25T21:02:49.136460Z",
     "shell.execute_reply.started": "2024-06-25T21:02:49.120239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.adaptive.enabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee8a7f4-b95b-43dc-8a69-49cb5b9351be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:03:41.538324Z",
     "iopub.status.busy": "2024-06-25T21:03:41.537814Z",
     "iopub.status.idle": "2024-06-25T21:03:41.547428Z",
     "shell.execute_reply": "2024-06-25T21:03:41.546491Z",
     "shell.execute_reply.started": "2024-06-25T21:03:41.538296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b400c1-50cf-4426-bcbc-bd0f1a19840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f729a25b-ff58-442e-817d-1529aa04a449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:31:16.917560Z",
     "iopub.status.busy": "2024-06-25T21:31:16.916610Z",
     "iopub.status.idle": "2024-06-25T21:31:16.933112Z",
     "shell.execute_reply": "2024-06-25T21:31:16.932216Z",
     "shell.execute_reply.started": "2024-06-25T21:31:16.917511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('true', 'true', None, '0b', 'true')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark.conf.set('spark.sql.adaptive.enabled', False)\n",
    "#spark.conf.set('spark.sql.adaptive.enabled', True)\n",
    "spark.conf.get('spark.sql.adaptive.enabled'), \\\n",
    "spark.conf.get('spark.sql.adaptive.coalescePartitions.enabled'), \\\n",
    "spark.conf.get('spark.sql.adaptive.autoBroadcastJoinThreshold'), \\\n",
    "spark.conf.get('spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold'), \\\n",
    "spark.conf.get('spark.sql.adaptive.skewJoin.enabled'), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835b714-45a1-40aa-8a93-5dd7c26ef552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T21:33:05.547242Z",
     "iopub.status.busy": "2024-06-25T21:33:05.546985Z",
     "iopub.status.idle": "2024-06-25T21:33:05.551666Z",
     "shell.execute_reply": "2024-06-25T21:33:05.550892Z",
     "shell.execute_reply.started": "2024-06-25T21:33:05.547229Z"
    }
   },
   "source": [
    "## There are quite a few properties related to Adatptive Execution:\n",
    "* Coalescing Post Shuffle Partitions (`spark.sql.adaptive.coalescePartitions.enabled`)\n",
    "* Converting sort-merge join to broadcast join (`spark.sql.adaptive.autoBroadcastJoinThreshold`)\n",
    "* Converting sort-merge join to shuffled hash join (`spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold`)\n",
    "* Optmizing skew join (`spark.sql.adaptive.skewJoin.enabled`)\n",
    "\n",
    "* `sort-merge` join, `shuffled hash` join - both are `reduce side` join"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
